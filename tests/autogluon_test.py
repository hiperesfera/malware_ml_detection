#!/usr/bin/env python3

import pandas as pd
from sklearn.model_selection import train_test_split
from autogluon.tabular import TabularPredictor

data_malware = pd.read_csv("final_bad_with_CFG.csv")
cols_to_drop = ['Filename','MD5','Machine']
unnamed_cols = list(data_malware.filter(regex='^Unnamed').columns) + list(data_malware.filter(regex='^CFG').columns)
#CFG_cols = list(data_malware.filter(regex='^CFG').columns)

dataClean_malware = data_malware.drop(columns= cols_to_drop + unnamed_cols)
dataClean_malware = dataClean_malware[:1200]

"""
dataClean_malware = dataClean_malware.drop(columns= ['SizeOfOptionalHeader', 'Characteristics', 'MajorLinkerVersion',
       'MinorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData',
       'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode',
       'BaseOfData', 'ImageBase', 'SectionAlignment', 'FileAlignment',
       'MajorOperatingSystemVersion', 'MinorOperatingSystemVersion',
       'MajorImageVersion', 'MinorImageVersion', 'MajorSubsystemVersion',
       'MinorSubsystemVersion', 'SizeOfImage', 'SizeOfHeaders', 'CheckSum',
       'Subsystem', 'DllCharacteristics', 'SizeOfStackReserve',
       'SizeOfStackCommit', 'SizeOfHeapReserve', 'SizeOfHeapCommit',
       'LoaderFlags', 'NumberOfRvaAndSizes', 'SectionsNb',
       'SectionsMeanEntropy', 'SectionsMinEntropy', 'SectionsMaxEntropy',
       'SectionsMeanRawsize', 'SectionsMinRawsize', 'SectionMaxRawsize',
       'SectionsMeanVirtualsize', 'SectionsMinVirtualsize',
       'SectionMaxVirtualsize', 'ImportsNbDLL', 'ImportsNb',
       'ImportsNbOrdinal', 'ExportNb'])
"""

print(dataClean_malware.columns)
print(dataClean_malware.shape)

data_nonmalware = pd.read_csv("pe_cfg_features_good.csv")
cols_to_drop = ['Filename','MD5','Machine']
unnamed_cols = list(data_nonmalware.filter(regex='^Unnamed').columns) + list(data_malware.filter(regex='^CFG').columns)
#CFG_cols = list(data_nonmalware.filter(regex='^CFG').columns)
dataClean_nonmalware = data_nonmalware.drop(columns= cols_to_drop + unnamed_cols) 
dataClean_nonmalware = dataClean_nonmalware[:1200]

"""
dataClean_nonmalware = dataClean_nonmalware.drop(columns= ['SizeOfOptionalHeader', 'Characteristics', 'MajorLinkerVersion',
       'MinorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData',
       'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode',
       'BaseOfData', 'ImageBase', 'SectionAlignment', 'FileAlignment',
       'MajorOperatingSystemVersion', 'MinorOperatingSystemVersion',
       'MajorImageVersion', 'MinorImageVersion', 'MajorSubsystemVersion',
       'MinorSubsystemVersion', 'SizeOfImage', 'SizeOfHeaders', 'CheckSum',
       'Subsystem', 'DllCharacteristics', 'SizeOfStackReserve',
       'SizeOfStackCommit', 'SizeOfHeapReserve', 'SizeOfHeapCommit',
       'LoaderFlags', 'NumberOfRvaAndSizes', 'SectionsNb',
       'SectionsMeanEntropy', 'SectionsMinEntropy', 'SectionsMaxEntropy',
       'SectionsMeanRawsize', 'SectionsMinRawsize', 'SectionMaxRawsize',
       'SectionsMeanVirtualsize', 'SectionsMinVirtualsize',
       'SectionMaxVirtualsize', 'ImportsNbDLL', 'ImportsNb',
       'ImportsNbOrdinal', 'ExportNb'])
"""

print(dataClean_nonmalware.columns)
print(dataClean_nonmalware.shape)

data = pd.concat([dataClean_malware, dataClean_nonmalware], axis=0)

input("Press Enter to continue...")

# Manually split the data: 80% for training and 20% for testing.
train_data, test_data = train_test_split(data, test_size=0.2, shuffle=True)

# Train the model on the training data.
predictor = TabularPredictor(label="malware", log_to_file=True).fit(train_data, presets='medium')

# Make predictions on the test data.
predictions = predictor.predict(test_data)

#evaluate in test data
#predictor.evaluate(test_data, silent=True)
#print(predictor.leaderboard(test_data))



