#!/usr/bin/env python3

from pandas import read_csv
import matplotlib 
import sklearn 
from sklearn.metrics import accuracy_score
import timeit
import joblib
from sklearn.model_selection import train_test_split
from matplotlib import pyplot


url="Kaggle-data.csv"
dataset = read_csv(url)
#In the dataset you want to predict the legitimate class. 1 means benign-ware and 0 means malware. The rest of the 
#data is the information that you will use for the prediction.

print("Data set size raw:", dataset.shape)


#Some things that yu don't need are the ID, md5, Machine
#Clean the dataset and remove these parts
#dataClean = dataset.drop(['ID','md5','Machine','Unnamed: 57'],axis=1)

# Explicit columns to drop
cols_to_drop = ['ID', 'md5', 'Machine', 'ResourcesNb', 'ResourcesMeanEntropy','ResourcesMinEntropy', 'ResourcesMaxEntropy', 'ResourcesMeanSize','ResourcesMinSize', 'ResourcesMaxSize', 'LoadConfigurationSize', 'VersionInformationSize']

# Get columns that start with 'Unnamed'
unnamed_cols = list(dataset.filter(regex='^Unnamed').columns)

# Drop these columns from the dataset
dataClean = dataset.drop(columns= cols_to_drop + unnamed_cols)

#For the example we reduce the dataset from 216351 to 10000 instances, you can change this in your 
#final experiments and add more data

dataCleanReduce = dataClean.sample(n=5000)

print("Data set size train:", dataCleanReduce.shape)

array= dataCleanReduce.values
# X are the columns that we are going to use for training the classifier
X = array[:, :-1]
# Y is the column that we will try to predict (legitimate) this says whether a piece of software is malware or not 
Y = array[:, -1]

#We have some data for training and some data for the final evaluation
#The classifier will learn from the training data and will be evaluated with the test data
#This will reduce overfitting

#Normally when you split the dataset you have 80% for training and 20% for test
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=1, shuffle=True)

#We are going to create our machine learning models with the classifiers

#Classifiers
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
#This is a list of models and each of them is going to be a classifier
models=[]
models.append(("Tree",DecisionTreeClassifier()))
#models.append(("KNN",KNeighborsClassifier()))
#models.append(("LDiscrimination",LinearDiscriminantAnalysis()))
#models.append(("NB",GaussianNB()))
#models.append(("SVM",SVC(gamma="auto")))
#models.append(("LRegression",LogisticRegression(solver="liblinear",multi_class="ovr")))
models.append(("RandomForest",RandomForestClassifier()))
#models.append(("GradientBoosting",GradientBoostingClassifier()))
#models.append(("AdaBoost",AdaBoostClassifier()))
models.append(("XGBoost",XGBClassifier()))
#models.append(("NNet",MLPClassifier(random_state=1, max_iter=300)))
#models.append(("OneRule",StackingClassifier()))
#This list will accumulate the results
results=[]
names = []

for name, model in models:
        #Normally you divide the training data in 10 blocks (or n blocks) and you use 9 for training and one
        #for testing, then you change the blocks 10 times and you choose form the 10 models that you have 
        #created the best one. This reduces overfitting
        start=timeit.default_timer()
        cv_fold= StratifiedKFold(n_splits=10,random_state=1,shuffle=True)
        cv_results= cross_val_score(model, X_train,Y_train,cv=cv_fold, scoring="accuracy")

        model.fit(X_train, Y_train)  # Train the model
        # Save the model to a file
        joblib.dump(model, f"{name}_model.pkl")
        print(f"{name} model saved as {name}_model.pkl")

        stop=timeit.default_timer()
        results.append(cv_results)
        names.append(name)
        print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))
        print("Time: ",stop-start)

#This is to create a plot comparing the accuracy of the different classifiers

"""
pyplot.boxplot(results, tick_labels=names)
pyplot.title("Malware Detector Comparison")
pyplot.xticks(rotation='vertical')
pyplot.show()
"""

# Step 1: Load the saved model
loaded_model = joblib.load("XGBoost_model.pkl")

# Step 2: Use the model to make predictions on the test set
predictions = loaded_model.predict(X_test)

# Step 3: Calculate accuracy
accuracy = accuracy_score(Y_test, predictions)

# Step 4: Print the accuracy
print(f"Accuracy on test data: {accuracy:.4f}")
