#!/usr/bin/env python3
import os
import pefile
import hashlib
import math
import statistics
import pandas as pd
import argparse

def compute_entropy(data):
    """Calculate entropy of a given byte sequence."""
    if not data:
        return 0.0
    occurences = [0] * 256
    for byte in data:
        occurences[byte] += 1
    total = len(data)
    probabilities = [float(occ) / total for occ in occurences if occ > 0]
    return -sum(p * math.log2(p) for p in probabilities)

def extract_pe_info(file_path):
    """Extract PE metadata and characteristics."""
    try:
        pe = pefile.PE(file_path)

        # Compute MD5 hash
        with open(file_path, "rb") as f:
            md5_hash = hashlib.md5(f.read()).hexdigest()

        # Get general PE characteristics
        optional_header = pe.OPTIONAL_HEADER
        file_header = pe.FILE_HEADER

        pe_info = {
            "Filename": os.path.basename(file_path),
            "MD5": md5_hash,
            "Machine": file_header.Machine,
            "SizeOfOptionalHeader": file_header.SizeOfOptionalHeader,
            "Characteristics": file_header.Characteristics,
            "MajorLinkerVersion": optional_header.MajorLinkerVersion,
            "MinorLinkerVersion": optional_header.MinorLinkerVersion,
            "SizeOfCode": optional_header.SizeOfCode,
            "SizeOfInitializedData": optional_header.SizeOfInitializedData,
            "SizeOfUninitializedData": optional_header.SizeOfUninitializedData,
            "AddressOfEntryPoint": optional_header.AddressOfEntryPoint,
            "BaseOfCode": optional_header.BaseOfCode,
            "BaseOfData": getattr(optional_header, "BaseOfData", 0),  # PE32 only
            "ImageBase": optional_header.ImageBase,
            "SectionAlignment": optional_header.SectionAlignment,
            "FileAlignment": optional_header.FileAlignment,
            "MajorOperatingSystemVersion": optional_header.MajorOperatingSystemVersion,
            "MinorOperatingSystemVersion": optional_header.MinorOperatingSystemVersion,
            "MajorImageVersion": optional_header.MajorImageVersion,
            "MinorImageVersion": optional_header.MinorImageVersion,
            "MajorSubsystemVersion": optional_header.MajorSubsystemVersion,
            "MinorSubsystemVersion": optional_header.MinorSubsystemVersion,
            "SizeOfImage": optional_header.SizeOfImage,
            "SizeOfHeaders": optional_header.SizeOfHeaders,
            "CheckSum": optional_header.CheckSum,
            "Subsystem": optional_header.Subsystem,
            "DllCharacteristics": optional_header.DllCharacteristics,
            "SizeOfStackReserve": optional_header.SizeOfStackReserve,
            "SizeOfStackCommit": optional_header.SizeOfStackCommit,
            "SizeOfHeapReserve": optional_header.SizeOfHeapReserve,
            "SizeOfHeapCommit": optional_header.SizeOfHeapCommit,
            "LoaderFlags": optional_header.LoaderFlags,
            "NumberOfRvaAndSizes": optional_header.NumberOfRvaAndSizes,
        }

        # Extract Sections information
        sections = pe.sections
        entropy_values = [compute_entropy(section.get_data()) for section in sections]
        raw_sizes = [section.SizeOfRawData for section in sections]
        virtual_sizes = [section.Misc_VirtualSize for section in sections]

        pe_info.update({
            "SectionsNb": len(sections),
            "SectionsMeanEntropy": statistics.mean(entropy_values) if entropy_values else 0,
            "SectionsMinEntropy": min(entropy_values, default=0),
            "SectionsMaxEntropy": max(entropy_values, default=0),
            "SectionsMeanRawsize": statistics.mean(raw_sizes) if raw_sizes else 0,
            "SectionsMinRawsize": min(raw_sizes, default=0),
            "SectionMaxRawsize": max(raw_sizes, default=0),
            "SectionsMeanVirtualsize": statistics.mean(virtual_sizes) if virtual_sizes else 0,
            "SectionsMinVirtualsize": min(virtual_sizes, default=0),
            "SectionMaxVirtualsize": max(virtual_sizes, default=0),
        })

        # Extract Import table information
        try:
            import_dlls = len(pe.DIRECTORY_ENTRY_IMPORT)
            import_entries = sum(len(entry.imports) for entry in pe.DIRECTORY_ENTRY_IMPORT)
            ordinal_imports = sum(1 for entry in pe.DIRECTORY_ENTRY_IMPORT for imp in entry.imports if imp.ordinal)
        except AttributeError:
            import_dlls, import_entries, ordinal_imports = 0, 0, 0

        pe_info.update({
            "ImportsNbDLL": import_dlls,
            "ImportsNb": import_entries,
            "ImportsNbOrdinal": ordinal_imports,
        })

        # Extract Export table information
        try:
            export_nb = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)
        except AttributeError:
            export_nb = 0

        pe_info["ExportNb"] = export_nb

        # Extract Resources information
        try:
            resources = pe.DIRECTORY_ENTRY_RESOURCE.entries
            resource_sizes = [entry.directory.entries[0].data.struct.Size for entry in resources if entry.directory]
            resource_entropies = [compute_entropy(pe.get_data(entry.directory.entries[0].data.struct.OffsetToData, entry.directory.entries[0].data.struct.Size)) for entry in resources if entry.directory]
        except AttributeError:
            resource_sizes = []
            resource_entropies = []

        pe_info.update({
            "ResourcesNb": len(resource_sizes),
            "ResourcesMeanEntropy": statistics.mean(resource_entropies) if resource_entropies else 0,
            "ResourcesMinEntropy": min(resource_entropies, default=0),
            "ResourcesMaxEntropy": max(resource_entropies, default=0),
            "ResourcesMeanSize": statistics.mean(resource_sizes) if resource_sizes else 0,
            "ResourcesMinSize": min(resource_sizes, default=0),
            "ResourcesMaxSize": max(resource_sizes, default=0),
        })

        # Extract Load Configuration & Version Information
        pe_info["LoadConfigurationSize"] = getattr(pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY["IMAGE_DIRECTORY_ENTRY_LOAD_CONFIG"]], "Size", 0)
        pe_info["VersionInformationSize"] = getattr(pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY["IMAGE_DIRECTORY_ENTRY_RESOURCE"]], "Size", 0)

        return pe_info

    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

def process_folder(folder_path, output_csv):
    """Process all PE files in a folder and save to CSV."""
    pe_data = []
    
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if os.path.isfile(file_path) and filename.lower().endswith(".exe"):
            print(f"Processing {filename}...")
            pe_info = extract_pe_info(file_path)
            if pe_info:
                pe_data.append(pe_info)

    # Save to CSV
    df = pd.DataFrame(pe_data)
    df.to_csv(output_csv, index=False)
    print(f"\nExtraction complete! Data saved to {output_csv}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Extract PE metadata from a folder of executables.")
    parser.add_argument("folder", help="Path to the folder containing PE files")
    parser.add_argument("-o", "--output", default="pe_metadata.csv", help="Output CSV file name (default: pe_metadata.csv)")
    
    args = parser.parse_args()
    
    if not os.path.isdir(args.folder):
        print(f"Error: The folder '{args.folder}' does not exist.")
    else:
        process_folder(args.folder, args.output)
